{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "from tqdm import tqdm\n",
        "\n",
        "with open(\"/content/drive/MyDrive/2023 Orientation/HW.txt\", 'r', encoding = 'utf-8') as f:\n",
        "  sources = f.read()\n",
        "output = \"/content/drive/MyDrive/2023 Orientation/HW_processed.txt\"\n",
        "\n",
        "with open(output, 'w', encoding = 'utf-8') as f:\n",
        "    corpus = []\n",
        "    data = \" \".join(jieba.cut(sources, cut_all = False, HMM = True))\n",
        "    corpus.append(data)\n",
        "\n",
        "    f.write(\" \".join(corpus) + '\\\\n')"
      ],
      "metadata": {
        "id": "WrT3GHSslB8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus"
      ],
      "metadata": {
        "id": "MsJPACg9suTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import word2vec\n",
        "\n",
        "model_name = \"test_model\"\n",
        "\n",
        "vector_size = 200\n",
        "min_count = 3\n",
        "window_size = 3\n",
        "workers = 8\n",
        "\n",
        "sentences = word2vec.LineSentence(output)"
      ],
      "metadata": {
        "id": "DnOPrLUWiXNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(sentences)"
      ],
      "metadata": {
        "id": "gGaNAo-fnqTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = word2vec.Word2Vec(\n",
        "    sentences,\n",
        "    vector_size = vector_size,\n",
        "    min_count = min_count,\n",
        "    window = window_size,\n",
        "    workers = workers\n",
        ")\n",
        "\n",
        "model.save(model_name)"
      ],
      "metadata": {
        "id": "hXugfMmUjPPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models.doc2vec import TaggedDocument\n",
        "from gensim.models import Doc2Vec\n",
        "\n",
        "tagged_data = [TaggedDocument(words = doc, tags = [str(i)]) for i, doc in enumerate(sentences)]\n"
      ],
      "metadata": {
        "id": "8Lwrxpw0vacd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_size = 100\n",
        "window = 5\n",
        "min_count = 1\n",
        "workers = 4\n",
        "\n",
        "model = Doc2Vec(\n",
        "    vector_size = vector_size,\n",
        "    window = window,\n",
        "    min_count = min_count,\n",
        "    workers = workers\n",
        ")"
      ],
      "metadata": {
        "id": "o3021oLDxSEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build_vocab(tagged_data)\n",
        "model.train(tagged_data, total_examples = model.corpus_count, epochs = model.epochs)"
      ],
      "metadata": {
        "id": "m1MPWiN8j0pZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_document = [\"世大運\", \"在\", \"成都\", \"正式\", \"拉開\", \"序幕\"]\n",
        "test_vector = model.infer_vector(test_document)\n",
        "\n",
        "similar_docs = model.docvecs.most_similar([test_vector], topn = 2)\n",
        "for doc_id, similarity in similar_docs:\n",
        "  doc_content = ' '.join(list(sentences)[int(doc_id)])\n",
        "  print(f'相似度: {similarity:.2f}，文檔標籤: {doc_id}，文檔內容: {doc_content}')\n",
        "\n",
        "model.save('doc2vec_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvg6B00gyl6z",
        "outputId": "c878dcb9-9807-4285-96bf-168e59f197c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "相似度: 0.12，文檔標籤: 2，文檔內容: 台灣 本屆 最大 獎牌 庫 是 網球 ， 獲 5 金 、 1 銀 、 1 銅牌 ， 5 金是 混雙 、 男雙 、 女雙 、 男團 及 女團 摘下 ， 整隊 收下 885 萬 。\n",
            "相似度: 0.08，文檔標籤: 7，文檔內容: 被 視為 奪金 熱門 的 羅 嘉翎 ， 這次 在世 大運 女子 57 公斤 決賽 抱憾 奪銀 ， 成為 最 令人 意外 的 結果 ， 但 她 的 對 手南 韓金 允珍 是 2016 年 世錦賽 及 上 屆 拿 坡 里 世大運 金牌得主 ， 廖家興 表示 ， 兩人 都 熟悉 彼此 ， 在 實力 旗鼓 相當 情況 下 ， 還是 得 看 臨場 發揮 ， 「 比賽 就是 有輸 有贏 ， 就是 太想 贏而過 於 急躁 。 」\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-69-2894f2b1162d>:4: DeprecationWarning: Call to deprecated `docvecs` (The `docvecs` property has been renamed `dv`.).\n",
            "  similar_docs = model.docvecs.most_similar([test_vector], topn = 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec = model.wv['世大運']\n",
        "print(vec.shape)\n",
        "vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PekwA0voz8AZ",
        "outputId": "d17bcd81-1b02-43ad-accd-d7712d43a585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.00703612, -0.00740568, -0.00818261,  0.00802115, -0.00346245,\n",
              "       -0.00821427, -0.0031433 ,  0.00780001, -0.00599089, -0.00557199,\n",
              "        0.00085238, -0.00513242, -0.00113936,  0.00209847, -0.00252762,\n",
              "        0.00742021,  0.00352317, -0.01118188,  0.00487787, -0.00780423,\n",
              "        0.00160912,  0.00378122, -0.00445518, -0.00253195,  0.00807809,\n",
              "       -0.00514216, -0.00921786,  0.00885365, -0.00499407, -0.00600987,\n",
              "        0.0115641 ,  0.00664101,  0.00395486,  0.00973053, -0.00874909,\n",
              "        0.00832433,  0.00134529,  0.00068638,  0.0015179 ,  0.00133803,\n",
              "        0.00486199,  0.00558428, -0.00453079, -0.00599078,  0.0002722 ,\n",
              "        0.00157063, -0.00371759,  0.00673961,  0.00614242,  0.00947071,\n",
              "        0.00228356,  0.00621824, -0.00112384,  0.00755678,  0.00247599,\n",
              "       -0.00736951, -0.00477671, -0.00269274,  0.0034322 , -0.00103579,\n",
              "       -0.00157118,  0.01023186,  0.00972794, -0.00178811, -0.00562956,\n",
              "       -0.00352605, -0.00209236, -0.00748988, -0.00056754, -0.00216453,\n",
              "        0.00096123,  0.00546273, -0.00334788, -0.01024215,  0.00255619,\n",
              "       -0.00374617,  0.00456342, -0.00456828,  0.00549077,  0.00127208,\n",
              "        0.00300649, -0.00070507, -0.00177948,  0.00970503, -0.00019729,\n",
              "       -0.00302011, -0.00732434,  0.00235635,  0.00793289,  0.00610484,\n",
              "       -0.00903288,  0.01204096,  0.00272984,  0.00693113,  0.01208624,\n",
              "       -0.00625416, -0.00839491,  0.00389469,  0.00949956,  0.00399683],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9d3CQWX40pRk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}